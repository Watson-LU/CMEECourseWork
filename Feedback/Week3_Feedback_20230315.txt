Starting code feedback for Jintao, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 4.48 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: .git, MiniProject, week7, week3, week2, Feedback, week1

Found the following files in parent directory: README.md, .gitignore

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
*~ 
*.tmp
*.log

## PYTHON TEMPLATE
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

## R TEMPLATE
# History files
.Rhistory
.Rapp.history

# Session Data files
.RData
.RDataTmp

# User-specific files
.Ruserdata

# Example code in package build process
*-Ex.R

# Output files from R CMD build
/*.tar.gz

# Output files from R CMD check
/*.Rcheck/

# RStudio files
.Rproj.user/

# produced vignettes
vignettes/*.html
vignettes/*.pdf

# OAuth2 token, see https://github.com/hadley/httr/releases/tag/v0.3
.httr-oauth

# knitr and R markdown default cache directories
*_cache/
/cache/

# Temporary files created by R markdown
*.utf8.md
*.knit.md

# R Environment Variables
.Renviron

# pkgdown site
docs/

# translation temp files
po/*~

# RStudio Connect folder
rsconnect/

**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
#My CMEE Coursework Repository

## Files in the CMEECourseWork
1. the feedback folder 
2. the README.md file
3. week1 folder
4. week2 folder
5. week3 folder
6. week4 folder --practices in the Data Management and Visualization module
7. week7 folder
8. Miniproject folder
...
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 4 weekly directories: week1, week2, week3, week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: code, sandbox, results, writeup, data

Found the following files: README2.md, README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README2.md

Printing contents of README2.md:

**********************************************************************
# Project name: Week4 R extra practice for Data Management and Visualization

## Brief Description
It's for the week3 extra R practices and works in the Data Management and Visualization module.
There are total Four practices in this section.

The first one is about modify the old DataWrang.R file to apply tidyverse package 
and renamed it with DataWrangTidy.R

The second task is create codes in PP_Dists.R that output three pdf which including few subplots selected by feeding types and a csv that including data about mean and median with predator mass, prey mass and their ratio.

The third assignment is to visualizing the regression analyses by coding in PP_Regress.R. Then, output a pdf to show the graph and a file PP_Regress_Results.csv to store the results. 

## Languages
Generally use bash and R that work in the both terminal and VSC.


## Dependencies and installation
Under this paractice, more packages are applied in the R.
1. the package "tidyverse"
```R
require("tidyverse")
```
2. the package"ggplot2"
```R
require("ggplot2")
```
3. the package"dplyr"
```R
require("dplyr")
```
4. the package"tidyr"
```R
require("tidyr")
```
5. the package"maps"
```R
require("maps")
```

## Project stucture and Usage

1. In the first practice, use tidyverse package instead of old method, as below using gather() than melt():
``` R
MyWrangledData<- gather(TempData,key = "Species",value="Count", -Cultivation,-Block,-Plot, -Quadrat,factor_key = TRUE)
```

To run the whole file obtain the results and find a csv file in the results folder
``` R
source("DataWrangTidy.R")
```

2. In this practice, first filter each attribute of Predator, prey and ratio under feeding types, for example in Predator.mass under insectivorous:
``` R
Pred_insectivorous <- filter(Mydf1, Type.of.feeding.interaction =="insectivorous")$Predator.mass
```
then to draw the histogram of this distribution:
```R
pdf("../results/Pred_Subplots.pdf", 12, 8)    
hist(log10(Pred_insectivorous),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'insectivorous feeding type')
dev.off()                                     
```
after plot all the graphs, calculate mean ,median of each factor using tidyverse and save it into a csv file:
```R
t1<- MyDF %>% 
        group_by(Type.of.feeding.interaction) %>% 
            summarise(Predator_mean= mean(Predator.mass),
            Predator_median= median(Predator.mass),
            Prey_mean=mean(Prey.mass),
            Prey_median= median(Prey.mass),
            ratio_mean= mean(Prey.mass/Predator.mass),
            ratio_median= median(Prey.mass/Predator.mass))

write.csv( t1, "../results/PP_Results.csv")
```

finally, run the whole code to clearly understanding, 
``` R
source("PP_Dists.R")
```

3. In this practice, the graph is plotted by ggplot package:

```R
p <- ggplot(MyDF, aes(x=log(Prey.mass),
                y=log(Predator.mass),
                colour = Predator.lifestage)) +theme_bw()
p1<- p+ xlab("Prey Mass in grams") +ylab("Predator Mass in grams")
p2<-p1 + geom_point(shape= I(3)) + facet_grid(Type.of.feeding.interaction ~.) 
p3<- p2 + geom_smooth(method="lm", fullrange=TRUE)
p3
```
then create a pdf to store it.
```R
pdf("../results/regression_analyses.pdf")
print(p3)
dev.off()
```
Ultimately, output the detailed linear model information into a csv file
```R
 t1<- MyDF %>% 
    group_by(Type.of.feeding.interaction,Predator.lifestage) %>% 
        summarise(intercept=lm(Predator.mass ~ Prey.mass)$coefficients[1][1],
        slope = lm(Predator.mass~Prey.mass)$coefficients[2][1],
        Ftest_value=lm(Predator.mass~Prey.mass$fstatistic),
        R_squared=cor.test(Prey.mass, Predator.mass)$estimate ** 2,
        p_value=cor.test(Prey.mass, Predator.mass)$p.value, na.rm = TRUE)
write.csv(t1,"../results/PP_Regress_Results.csv")
```

run the whole code to clearly understanding, 
```R
source("PP_Regress.R")
```
4. In the last practice, the goal is to print a world map and input some points on it. The maps() package is applied. core code as below:
```R
map(database = "world")
points(x=gpdd$lat, y = gpdd$long, col = "red")
```
the whole file is run by:
```R
source("GPDD_Data.R")
```

Finished

## Author name and Contact
Author name: Jintao Lu

Contact: jl8722@ic.ac.uk


**********************************************************************

Found following files in results directory: Girko.pdf, MyFirst-ggplot2-Figure.pdf, PP_Regress_Results.pdf, MyBars.pdf, MyData.csv, Pred_Subplots.pdf, MyLinReg.pdf, Sizeratio_Subplots.pdf, Pred_Prey_Overlay.pdf, PP_Regress_Results.csv, PP_Results.csv, TreeHts.csv, Prey_Subplots.pdf...

Ideally, Results directory should be empty other than, perhaps a .gitkeep. 

 0.5 pts deducted per results file 

Current Points = 93.5

Found 36 code files: apply2.R, apply1.R, Vectorize2.py, Girko.R, next.R, plotLin.R, Florida.R, sample.R, PP_Dists.R, get_TreeHeight.py, try.R, PP_Regress_loc.R, control_flow.R, TAutoCorr.R, is_Florida_getting_warmer.tex, Ricker.R, boilerplate.R, run_vectorized.sh, R_conditionals.R, Vectorize1.py, browse.R, GPDD_Data.R, PP_Regress.R, grahic.R, get_TreeHeight.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, break.R, run_get_TreeHeight.sh, DataWrang.R, compilelatex.sh, Mybars.R, TreeHeight.R, basic_io.R, Vectorize1.R

Found the following extra files: distribution around T.png
0.5 pt deducted per extra file

Current Points = 93.0

======================================================================
Testing script/code files...

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
SomeOperation <- function(v) {
    if (sum(v) >0) { #should be note that sum(v)is s single value
        return (v * 100)
    } else {
        return (v)
    }
}

M <- matrix(rnorm(100), 10,10)
print(apply(M,1,SomeOperation))

**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************
             [,1]      [,2]      [,3]       [,4]       [,5]        [,6]
 [1,]   -7.675278  33.66641 223.93097  0.8249272  0.7689911 -0.23796783
 [2,]  214.686148 -91.87529  10.54512 -0.2725962 -0.6961431 -1.35567029
 [3,]   95.830433 -56.22831  34.94377 -0.4081165  0.3470167 -0.02007752
 [4,] -243.506184 -70.85420 -34.65435 -0.9265957 -1.9324099 -2.01073983
 [5,] -103.335753  40.53924  95.57381 -0.3508583 -0.8749025  0.10215513
 [6,]  146.427663  30.72922 -97.45075  0.3810506  0.6261757 -1.796133
**********************************************************************

Code ran without errors

Time consumed = 0.19768s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
## Build a random matrix
M <-matrix(rnorm(100),10,10)

##take the mean of each row
RowMeans <- apply(M, 1, mean)
print(RowMeans)

##now the variance
RowVars <- apply(M,1,var)
print(RowVars)

##by column
ColMeans <- apply(M, 2, mean)
print(ColMeans)






**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1] -0.46946916 -0.26831309 -0.62706293 -0.06296326  0.36670021 -0.07657306
 [7] -0.12824598 -0.38188564  0.65124088 -0.71808653
 [1] 0.8053593 0.7384515 1.1260844 1.7126881 1.5429775 1.4022138 0.3238365
 [8] 1.6659089 0.7065184 1.0327038
 [1] -0.39789063  0.18040196 -0.04659339 -0.54012125 -0.40680444 -0.05308005
 [7]  0.07150019 -0.30513171  0.32882342 -0.54576267

**********************************************************************

Code ran without errors

Time consumed = 0.17816s

======================================================================
Inspecting script file Vectorize2.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

"""This script is the translated version of Vectorise2.py"""

__appname__ = 'Vectorize2'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import numpy as np 
import time

def stochrick(p0 = np.random.uniform(.5, 1.5, 1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs the stochastic Ricker equation with Gaussian fluctuations"""
    N = np.zeros((numyears, len(p0)))  #initial the empty matrix
    N[0] = p0

    # the loop 
    for pop in range(len(p0)):
        for yr in range(1, numyears):
            N[yr, pop] = N[yr - 1, pop] * np.exp(r * (1 - N[yr - 1, pop] / K) + np.random.normal(0, sigma, 1))
    return N


# Now write another function called stochrickvect that vectorizes the above function
def stochrickvect(p0 = np.random.uniform(.5, 1.5, 1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs vectorised version of above function"""
    N = np.zeros((numyears, len(p0)))  #same methods
    N[0] = p0 
    for yr in range(1, numyears):
        N[yr, ] = N[yr - 1, ] * np.exp(r * (1 - (N[yr - 1, ] / K)) + np.random.normal(0, sigma, size = 1))
    return N


# time stochrick
start = time.time()
stochrick()
end = time.time()
print("Non-vectorized Stochastic Ricker takes:")
print(end - start)

# time stochrickvect
start = time.time()
stochrickvect()
end = time.time()
print("Vectorized Stochastic Ricker takes:")
print(end - start)

print("vectorise2.py is done")
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 93.0

Output (only first 500 characters): 


**********************************************************************
Non-vectorized Stochastic Ricker takes:
0.6160852909088135
Vectorized Stochastic Ricker takes:
0.002318143844604492
vectorise2.py is done

**********************************************************************

Code ran without errors

Time consumed = 0.76027s

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
p

pdf("../results/Girko.pdf")
print(p)

dev.off()
**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(eigDF, aes(x = Real, y = Imaginary)) : 
  could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************


for (i in 1:10) {
  if ((i %% 2) == 0) # check if the number is odd
    next # pass to next iteration of loop 
  print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.20017s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************

x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")

p

pdf("../results/MyLinReg.pdf")
print(p)

dev.off()



**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(my_data, aes(x = x, y = y, colour = abs(my_lm$residual))) : 
  could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file Florida.R...

File contents are:

**********************************************************************

rm(list=ls())
#load the data file from data folder
load("../data/KeyWestAnnualMeanTemperature.RData")
ls()
class(ats)
head(ats)   #notify the data structure
# extract data from data set
temp<- c(ats$Temp)   
year<- c(ats$Year)

#calculate the correlation using original orders
Oricor<- cor(temp, year, method = "pearson")
Oricor

cat("the obtained correlation is", Oricor, '\n')

#calculate the correlation using randomly re-assigning temperature data

nreps<-5000     #to repeat 5000 times samples
T.random<-numeric(nreps)

for (i in 1:nreps) {
    Y <- year
    X <- sample(temp, 100, replace = FALSE)    #in total 100 numbers of data to sample
    T.random[i] <-cor(X,Y)    # store correlation results into T.random
}

#calculate the probablity of obeained one / sample one
prob <- length(T.random[T.random >= Oricor])/nreps

paste("probablity randomized correlation >= observed one is",prob)
#applying histogram to convince the audience
hist(T.random, breaks = 50, main =  expression(paste("Distribution around ",rho, "= 0")), xlab = "correlation from randomized samples")






**********************************************************************

Testing Florida.R...

Output (only first 500 characters): 


**********************************************************************
[1] "ats"
[1] "data.frame"
  Year     Temp
1 1901 23.75000
2 1902 24.66667
3 1903 24.71667
4 1904 24.51667
5 1905 24.88333
6 1906 24.63333
[1] 0.5331784
the obtained correlation is 0.5331784 
[1] "probablity randomized correlation >= observed one is 0"

**********************************************************************

Code ran without errors

Time consumed = 0.39606s

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}

## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}

## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}


## To run "num" iterations of the experiment using vectorization with list lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with vector sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}


set.seed(12345)
popn <- rnorm(10000)
#hist(popn)
n <- 100 #sample size for each experiment
num <- 10000 # number of times to return the experiment

print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))

print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))

print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))

print("Using the vectorized sapply function (on a vector) took:" )
print(system.time(sapply_sample(popn, n, num)))

print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))





**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops without preallocation on a vector took:"
   user  system elapsed 
  0.355   0.009   0.363 
[1] "Using loops with preallocation on a vector took:"
   user  system elapsed 
  0.222   0.000   0.223 
[1] "Using loops with preallocation on a list took:"
   user  system elapsed 
  0.222   0.000   0.223 
[1] "Using the vectorized sapply function (on a vector) took:"
   user  system elapsed 
  0.225   0.000   0.225 
[1] "Using the vectorized lapply function (on a list) took:"
   user  sy
**********************************************************************

Code ran without errors

Time consumed = 1.54045s

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
rm(list=ls())
##load the file and data
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")
dim(MyDF) #check the size of the data frame you loaded
str(MyDF)
head(MyDF)
#apply dplyr to tidy the data
require(tidyverse)
glimpse(MyDF)
## remember to turn some column to factor to set them as grouping variables.
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)
glimpse(MyDF)


## dataset of distributions of predator mass, prey mass, and the size ratio of prey mass over predator mass by feeding interaction type
glimpse(MyDF$Type.of.feeding.interaction)
Mydf1<- dplyr::as_tibble(MyDF)
Mydf1

##list all classified data into different sets
Pred_insectivorous <- filter(Mydf1, Type.of.feeding.interaction =="insectivorous")$Predator.mass
Pred_piscivorous<- filter(Mydf1, Type.of.feeding.interaction =="piscivorous")$Predator.mass
Pred_planktivorous<- filter(Mydf1, Type.of.feeding.interaction =="planktivorous")$Predator.mass
Pred_predacious<- filter(Mydf1, Type.of.feeding.interaction =="predacious")$Predator.mass
Pred_pp<- filter(Mydf1, Type.of.feeding.interaction =="predacious/piscivorous")$Predator.mass

Prey_insectivorous <- filter(Mydf1, Type.of.feeding.interaction =="insectivorous")$Prey.mass
Prey_piscivorous <- filter(Mydf1, Type.of.feeding.interaction =="piscivorous")$Prey.mass
Prey_planktivorous <- filter(Mydf1, Type.of.feeding.interaction =="planktivorous")$Prey.mass
Prey_predacious <- filter(Mydf1, Type.of.feeding.interaction =="predacious")$Prey.mass
Prey_pp <- filter(Mydf1, Type.of.feeding.interaction =="predacious/piscivorous")$Prey.mass

ratio_insectivorous<- c(Prey_insectivorous/Pred_insectivorous)
ratio_piscivorous<- c(Prey_piscivorous/Pred_piscivorous)
ratio_planktivorous<- c(Prey_planktivorous/Pred_planktivorous)
ratio_predacious<- c(Prey_predacious/Pred_predacious)
ratio_pp<- c(Prey_pp/Pred_pp)


#### 1.in Predator figure
pdf("../results/Pred_Subplots.pdf", 12, 8)     #open with create pdf
par(mfcol=c(2,3))                              #set the total subplot arrange
par(mfg = c(1,1))
hist(log10(Pred_insectivorous),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'insectivorous feeding type')
par(mfg = c(1,2))
hist(log10(Pred_piscivorous),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'piscivorous feeding type')
par(mfg = c(1,3))
hist(log10(Pred_planktivorous),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'planktivorous feeding type')
par(mfg = c(2,1))
hist(log10(Pred_predacious),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'predacious feeding type')
par(mfg = c(2,2))
hist(log10(Pred_pp),
    xlab = "log10(Predator Mass (g))", ylab = "Count", 
    main = 'predacious/piscivorous feeding type')
dev.off()                                               # turn off the pdf setting

#### 2.in Prey figure
pdf("../results/Prey_Subplots.pdf", 12, 8)
par(mfcol=c(2,3))
par(mfg = c(1,1))
hist(log10(Prey_insectivorous),
    xlab = "log10(Prey Mass (g))", ylab = "Count", 
    main = 'insectivorous feeding type')
par(mfg = c(1,2))
hist(log10(Prey_piscivorous),
    xlab = "log10(Prey Mass (g))", ylab = "Count", 
    main = 'piscivorous feeding type')
par(mfg = c(1,3))
hist(log10(Prey_planktivorous),
    xlab = "log10(Prey Mass (g))", ylab = "Count", 
    main = 'planktivorous feeding type')
par(mfg = c(2,1))
hist(log10(Prey_predacious),
    xlab = "log10(Prey Mass (g))", ylab = "Count", 
    main = 'predacious feeding type')
par(mfg = c(2,2))
hist(log10(Prey_pp),
    xlab = "log10(Prey Mass (g))", ylab = "Count", 
    main = 'predacious/piscivorous feeding type')
dev.off()

####3. in size ratio figure
pdf("../results/Sizeratio_Subplots.pdf", 12, 8)
par(mfcol=c(2,3))
par(mfg = c(1,1))
hist(log10(ratio_insectivorous),
    xlab = "log10(size ratio)", ylab = "Count", 
    main = 'insectivorous feeding type')
par(mfg = c(1,2))
hist(log10(ratio_piscivorous),
    xlab = "log10(size ratio)", ylab = "Count", 
    main = 'piscivorous feeding type')
par(mfg = c(1,3))
hist(log10(ratio_planktivorous),
    xlab = "log10(size ratio)", ylab = "Count", 
    main = 'planktivorous feeding type')
par(mfg = c(2,1))
hist(log10(ratio_predacious),
    xlab = "log10(size ratio)", ylab = "Count", 
    main = 'predacious feeding type')
par(mfg = c(2,2))
hist(log10(ratio_pp),
    xlab = "log10(size ratio)", ylab = "Count", 
    main = 'predacious/piscivorous feeding type')
dev.off()

##dealing with csv file

##apply dplyr to arrange the data in the data frame and do the calculate of mean and median
t1<- MyDF %>% 
        group_by(Type.of.feeding.interaction) %>% 
            summarise(Predator_mean= mean(Predator.mass),
            Predator_median= median(Predator.mass),
            Prey_mean=mean(Prey.mass),
            Prey_median= median(Prey.mass),
            ratio_mean= mean(Prey.mass/Predator.mass),
            ratio_median= median(Prey.mass/Predator.mass))

t1
#write the results into file store in results floder
write.csv( t1, "../results/PP_Results.csv")

**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************
[1] 34931    15
'data.frame':	34931 obs. of  15 variables:
 $ Record.number              : int  1 2 3 4 5 6 7 8 9 10 ...
 $ In.refID                   : chr  "ATSH063" "ATSH080" "ATSH089" "ATSH143" ...
 $ IndividualID               : chr  "1" "2" "3" "4" ...
 $ Predator                   : chr  "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" ...
 $ Predator.common.name       : chr  "Atlantic sharpnose shark" "Atlantic sharpnose s
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

"""This script is python version of get_TreeHeight.R"""

__appname__ = 'get_TreeHeight.py'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import sys
import numpy as np
import csv


def Cal_TH(degrees, distance):
    """Calculates the height of a tree given distance of each tree
    from its base and angle to its top, using the trigonometric formula"""

    radians = degrees * np.pi / 180
    height = distance * np.tan(radians)

    return height

def main(argv):
    """Main entry point of program"""
    try:
        input = sys.argv[1]
    except (FileNotFoundError, IndexError) as error:
        print("Your input is nonsense! We will work on trees.csv file.")
        input = "../data/trees.csv"

    
    Treedata = []
     
    with open(input) as f:
    # Append file to list
      mydata = csv.reader(f)

      for row in mydata:
          Treedata.append(row)

    # Add tree heights to list
    Treedata[0].append("Tree.Height.m")

    for i in range(1, len(Treedata)):
        Treedata[i].append(Cal_TH( float(Treedata[i][2]), float(Treedata[i][1]) ))
    
    path = "../results/" + input.split("/")[2].split(".")[0] + "_treeheights.csv"

    w = open(path, 'w')
    write = csv.writer(w)
    for row in Treedata:
        write.writerow(row)
          

if __name__ == '__main__':
    status = main(sys.argv)
    sys.exit(status)
**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 93.0

Output (only first 500 characters): 


**********************************************************************
Your input is nonsense! We will work on trees.csv file.

**********************************************************************

Code ran without errors

Time consumed = 0.14660s

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************

doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
        } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }

set.seed(1345) ##get the game values to illustration
popn <-rnorm(50)

hist(popn)

lapply(1:15 , function(i) doit(popn))

result <- lapply(1:15, function(i) try(doit(popn), FALSE))
**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: -0.11620822588674"
[1] "Mean of this sample was: -0.0468516755995931"
[1] "Mean of this sample was: -0.0890228211466614"
[1] "Mean of this sample was: -0.124229742255296"

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in doit(popn) : Couldn't calculate mean: too few unique values!
Calls: lapply -> FUN -> doit
Execution halted

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: PP_Regress_loc.R
# Date: Dec 2022
# Desc: 
# Do the same thing as PP_Regress.R, but the analysis this time
# should be separate by the dataset’s Location field.

rm(list=ls())  #empty the all variables

#1a. load package
require(tidyverse)

#1b. import dataset
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

#------------------------------------
##calculating regression statistic
#2a.
for (i in 1:nrow(MyDF)){
    if(MyDF$Prey.mass.unit[i] == "mg"){
        MyDF$Prey.mass.unit[i] <- "g"   # chenge with mg to g
        MyDF$Prey.mass[i] <- MyDF$Prey.mass[i] / 1000 # change the number correctly
    }
}

#2b. Feeding, lifestage and location subgroups
FLL_groups <- MyDF %>% group_by(Type.of.feeding.interaction,Predator.lifestage,Location) %>% count()

#2c. running linear model
linear_models <- MyDF %>% 
  group_by(Type.of.feeding.interaction,Predator.lifestage,Location) %>%
  do(model = lm(Predator.mass ~ Prey.mass, data= .))

#2d. creating table
FLL_stats <- data.frame(Feeding_Type = FLL_groups$Type.of.feeding.interaction,
                        Predator_Lifestage=FLL_groups$Predator.lifestage,
                        Location =FLL_groups$Location,
                        Intercept=NA,Slope=NA,P_value_overall=NA, R_squared=NA,
                        F_statistic=NA)

#2e. excluding rows with sample size of 5 or less
  #too few data points for accurate sample size
#examining rows to exclude
FLL_groups[FLL_groups$n <= 5,]
#   Type.of.feeding.interaction Predator.lifestage Location                n
# 1 piscivorous                 postlarva/juvenile Antarctic Peninsula     2
# 2 planktivorous               juvenile           Gulf of Alaska          2
# 3 predacious                  adult              Gulf of Maine, New England     5
#row numbers of rows to exclude
which(FLL_groups$n <= 5,) #21 24 36
#row numbers of rows to include - to calculate statistics for
i_values <- c(1:nrow(FLL_groups))[-which(FLL_groups$n <= 5,)]

#2f. combining results into table
for (i in i_values){
#for (i in c(1:20,22:23,25:35,37:nrow(FLL_groups))){
  #browser()
  FLL_stats[i,"Intercept"] <- summary(linear_models$model[[i]])$coef[1,1] #Intercept
  FLL_stats[i,"Slope"] <- summary(linear_models$model[[i]])$coef[2,1]  # slope
  FLL_stats[i,"P_value_overall"] <- summary(linear_models$model[[i]])$coef[2,4]  #p value, slope significance
  FLL_stats[i,"R_squared"] <- summary(linear_models$model[[i]])$r.squared #r squared
  FLL_stats[i,"F_statistic"] <- summary(linear_models$model[[i]])$fstatistic[[1]] #f statistic
}

#2g. making results csv 
write.csv(FLL_stats, "../results/PP_Regress_loc_Results.csv")


print("Script complete!")
**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 


**********************************************************************
# A tibble: 3 x 4
# Groups:   Type.of.feeding.interaction, Predator.lifestage, Location [3]
  Type.of.feeding.interaction Predator.lifestage Location                      n
  <chr>                       <chr>              <chr>                     <int>
1 piscivorous                 postlarva/juvenile Antarctic Peninsula           2
2 planktivorous               juvenile           Gulf of Alaska                2
3 predacious                  adult              Gulf of Maine, New Engla…     5
[1] 
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Warning messages:
1: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
2: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
3: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
4: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
5: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
6: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
7: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
8: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
9: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
10: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
##if statements

a <- TRUE
if (a == TRUE) {
    print ("a is TRUE")
} else {
    print ("a is FALSE")
}

#write in a single line, just set it in a line.....so silly
z <- runif(1) ## Generate a uniformly distributed random number
if (z <= 0.5) {print ("Less than a half")}


## in a for loop
for (i in seq(10)) {
    j <- i * i
    print(paste(i, " squared is", j )) # nolint
}


for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')) {
      print(paste('The species is', species))
}

#use for loop by pre-existing vector  
v1 <- c("a", "b","c")
for (i in v1) {print(i)}

##while loops

i <- 0
while (i < 10) {
    i <- i+1
    print(i^2)
}









**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "a is TRUE"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "b"
[1] "c"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.20550s

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: TAutoCorr.R
# Date: Dec 2022
# Desc:
# Groupwork Practical: Autocorrelation in Florida weather
# Are temperatures of one year significantly correlated with
# the next year (successive years), across years in Florida?

rm(list = ls())

require(ggplot2)

# view the data
load("../data/KeyWestAnnualMeanTemperature.RData")
pdf("../results/TAutoCorrPlot1.pdf")
plot(ats, main = "Temperature in Florida between 1990-2000")
dev.off()

# permutation test
# test statistic: correlation coefficient between year and temperature
# null hypothesis: Temperatures of one year isn't correlated with the next year across years in Florida
# alternative htpothesis: Temperatures of one year is correlated with the next year across years in Florida
# permutation set: 10000 shuffles of ats$Temp

n <- length(ats$Year) # the total number of years

# get the temperature of successive years
temp_1 <- c(ats[1:(n - 1), 2]) # temperature from year 1 to year 99
temp_2 <- c(ats[2:n, 2]) # temperature from year 2 to year 100

# calculate the correlation between temp_1 and temp_2
temp_cor <- cor(temp_1, temp_2) 

# starting shuffling
cor_of_random <- c()
N <- 10000
# apply the loop to reach as many as time to see the most results
for (i in 1:N) {
    random_sample <- sample(ats$Temp, n, replace = F) 
    temp_1 <- random_sample[1:(n - 1)]
    temp_2 <- random_sample[2:n]
    cr <- cor(temp_1, temp_2)
    cor_of_random <- c(cor_of_random, cr)
}


pdf("../results/TAutoCorrplot2.pdf")
# show the distribution of two parameters'correlation through 10000 times
hist(cor_of_random,
     xlab = "Random correlation coefficients",
     main = "Histogram of Random Correlation Coefficients")
abline(v=temp_cor, col="red")
dev.off()

# hint: you can’t use the standard p-value calculated for a correlation coefficient, 
# because measurements of climatic variables in successive time-points in a time series 
# (successive seconds, minutes, hours, months, years, etc.) are not independent.
estimated_p <- sum(cor_of_random[cor_of_random >= temp_cor]) / length(cor_of_random)

print(paste("The estimated p-value is: ", estimated_p))
# [1] "The estimated p-value is:  0.000108006045209073"
# p-value < 0.05, reject null hypothesis, accept alternative htpothesis

# Results: Temperatures of one year is correlated with the next year across years in Florida
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************
null device 
          1 
null device 
          1 
[1] "The estimated p-value is:  0"

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file is_Florida_getting_warmer.tex...

File contents are:

**********************************************************************
\documentclass[8pt]{article}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[a4paper, total={6in, 8in}]{geometry}

\title{Is Florida Getting Warmer}

\begin{document}
    \section{The interperation of whether Florida getting warmer or not}
    \begin{lstlisting}[language=R]
        #after load the data file, take the data into sets
        temp<- c(ats$Temp)
        year<- c(ats$Year)
        #observed coorelation between temperature and year
        Oricor<- cor(temp, year, method = "pearson")
        Oricor

        #using 5000 generation to simulate random situation
        nreps<-5000
        T.random<-numeric(nreps)
            
        #in each generation, calculate the correlation between two factors
        for (i in 1:nreps) {
            Y <- year
            X <- sample(temp, 100, replace = FALSE)   
            T.random[i] <-cor(X,Y)
        }
        #calculate the similar situation like observed one in the 
        #randon simulation
        prob <- length(T.random[T.random >= Oricor])/nreps
        #histgram the distribution of random one correlation
        hist(r.random, breaks = 50, main =  expression(paste(
            "Distribution around ",rho, "= 0")), 
            xlab = "correlation from randomized samples")
        \end{lstlisting}
    
    The code 'prob' showing nearly 0 possibility randomized temperature influence.
    Although the observed temperature is during a successive time-points, the comparison 
    between it and random time correlation showing that they have significant different.
    Thus, the 0.53 correlation inidcate the temperature has significant correlation with the years,
    which further indicate that Florida is getting warmer through the years. In addition, the
    graph below also showing the observed one is different with the random calculating one.
    
    \includegraphics[width=\textwidth]{distribution around T}
    
    This graphic showing that the observed correlation is larger than 0.5 which is nearly tend to 0.

\end{document}









**********************************************************************

Testing is_Florida_getting_warmer.tex...

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************

Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

plot(Ricker(generations=10), type="l")




**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.22519s

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# A boilerplate R script

MyFunction <- function(Arg1, Arg2) {
  
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
    
  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test

















**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.19218s

======================================================================
Inspecting script file run_vectorized.sh...

File contents are:

**********************************************************************
#!/bin/sh
# Author: 01_Awesome_Aardvarks
# Script: run_vectorized.sh
# Desc: run the R and python version of vectorize1 and vectorize2
# Arguments: none
# Date: Dec 2022

echo " output of Vectorize1.R"
Rscript Vectorize1.R

echo " output of Vectorize2.R"
Rscript Vectorize2.R

echo " output of Vectorize1.py"
python3 Vectorize1.py

echo "output of Vectorize2.py"
python3 Vectorize2.py

echo "finish the run time output"
**********************************************************************

Testing run_vectorized.sh...

Output (only first 500 characters): 


**********************************************************************
 output of Vectorize1.R
[1] "Using loops, he time taken is :"
   user  system elapsed 
  0.066   0.000   0.066 
[1] "Using the in-built vectorized function, the wimt taken is :"
   user  system elapsed 
  0.000   0.000   0.001 
 output of Vectorize2.R
[1] "Un-vectorized Stochastic Ricker of Vectorize2.R takes:"
   user  system elapsed 
  0.218   0.006   0.223 
[1] "Vectorized Stochastic Ricker of Vectorize2.R takes:"
   user  system elapsed 
  0.009   0.000   0.009 
 output of Vectorize1.py
after
**********************************************************************

Code ran without errors

Time consumed = 2.13293s

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************
##function with conditionals

#check if an integer is even
is.even <- function(n=2) {
    if (n %%2 ==2){
        return(paste(n,'is even!'))
    } else {
        return(paste(n, 'is odd!'))
    }
}


is.even(6)



# Checks if a number is a power of 2
is.power2 <- function(n = 2) {
  if (log2(n) %% 1==0) {
    return(paste(n, 'is a power of 2!'))
  } else {
  return(paste(n,'is not a power of 2!'))
    }
}

is.power2(4)

#check if a number is prime
is.prime <- function(n) {
    if (n ==0)   {
        return(paste(n ,'is a zero!'))
    }   else if (n==1)  {
        return(paste(n ,'is just a unit'))
    }


    ints <- 2:(n-1)

    if (all(n%%ints !=0))   {
        return(paste(n ,'is a prime'))
    }   else    {
        return(paste(n,'is a composite'))
    }

}

is.prime(3)
**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is odd!"
[1] "4 is a power of 2!"
[1] "3 is a prime"

**********************************************************************

Code ran without errors

Time consumed = 0.17598s

======================================================================
Inspecting script file Vectorize1.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

""" This script is the transfered version of Vectorise1.R"""

__appname__ = 'Vectorize1'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import numpy as np
import time
#create the random matrix
T = np.mat(np.random.randint(1000000,size=(1000,1000)))


def sumallelements(T):
    """Paremeters:
    T(matrix): the given matrix
    Returns:
        sum(float): sum all elements in M
    """
    dimension = T.shape
    Sum = 0
    for i in range(0,dimension[0]): #loop rows
        for j in range(0,dimension[1]): # loop columns
                Sum = Sum + T[i,j]
    return Sum

# time sumallelements
start = time.time()
sumallelements(T)  
end = time.time()
print("after the loop, time is:", end-start) 

# time sum function in numpy
start = time.time()
np.sum(T) # vectorized function
end = time.time()
print("after the vectorized function in numpy, the time is:", end - start)

print("vectorise1.py is done")
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 93.0

Output (only first 500 characters): 


**********************************************************************
after the loop, time is: 0.4659841060638428
after the vectorized function in numpy, the time is: 0.0006973743438720703
vectorise1.py is done

**********************************************************************

Code ran without errors

Time consumed = 0.67595s

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.22908s

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
rm(list=ls())  #empty all variables
#loead necessary packages
library(maps)
#loead the data file
load("../data/GPDDFiltered.RData")
ls()
class(gpdd)
head(gpdd)
str(gpdd)    #check the structure of data file


# use map package to draw the world map into R
map(database = "world")
#draw points that writing in the data frame.
points(x=gpdd$lat, y = gpdd$long, col = "red")

### comment:
# Since the projection of the earth is different, the points will be more
# accurate near the equator then the polar. Besides, the points is larger
# then the true points in the map which means a little point in the map 
# could represent Thousands of square Kilometer areas. Thus, the point drawn
# in that map could not reflect to the true location.

**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************
[1] "gpdd"
[1] "data.frame"
             common.name   lat    long
1        Atlantic salmon 60.00   10.00
2            Pink salmon 45.62 -121.97
3              Great tit 51.63    1.08
4 Eurasian oystercatcher 51.70   -5.15
5                Skylark 51.70   -5.15
6               Starling 51.70   -5.15
'data.frame':	147 obs. of  3 variables:
 $ common.name: Factor w/ 72 levels "American marten",..: 5 54 32 27 62 64 44 16 61 47 ...
 $ lat        : num  60 45.6 51.6 51.7 51.7 ...
 $ long       : num  
**********************************************************************

Code ran without errors

Time consumed = 0.26659s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
rm(list = ls()) # clean the environment
graphics.off() # shut down all open graphics devices
require(ggplot2) # load ggplot2 package
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv") # import csv data to a data frame

pdf("../results/PP_Regress_Results.pdf") # save the pdf file
p <- ggplot(MyDF, aes(x = Prey.mass,
                      y = Predator.mass,
                      colour = Predator.lifestage))
# create a graphics object p 
q <- p + scale_x_continuous("Prey Mass in grams", trans = 'log10') + 
  scale_y_continuous("Predator mass in grams", trans = 'log10') +
  geom_point(size=I(1), shape=I(3)) + geom_smooth(method = "lm", fullrange = TRUE) +
  theme_bw() + facet_grid(Type.of.feeding.interaction ~., scales = "free") + theme(legend.position = "bottom", legend.box = "horizontal") + theme(aspect.ratio = 0.4) + guides(color = guide_legend(nrow = 1))
# add layers and other plot elements
print(q)
dev.off() # close the graphic window

feedingTypes <- as.list(levels(MyDF$Type.of.feeding.interaction))
# convert factor to list
PredatorLifestage <- as.list(levels(MyDF$Predator.lifestage))
# convert factor to list again

## Initialize vectors ##
Regression_Slope <- c()
Regression_Intercept <- c()
Feeding_Type <- c()
Life_Stage <- c()
R_Squared <- c()
F_Statistic_Value <- c()
P_Value <- c()


for (i in feedingTypes){
  TempDF <- subset(MyDF, Type.of.feeding.interaction == i)
  # subset MyDF to TempDF according to every Type.of.feeding.interaction
  PredatorLifestage <- unique(TempDF$Predator.lifestage)
  # under each feeding type, extract the corresponding predator lifestage
  for (j in PredatorLifestage){
    TempDF1 <- subset(TempDF, Predator.lifestage == j)
    # subset TempDF to TempDF1 according to every existing predator lifestage
    modelTemp <- lm(Predator.mass~Prey.mass, data = TempDF1)
    # fit the linear regression model
    SumTemp <- summary(modelTemp)
    # use the summary function
    if (length(SumTemp$fstatistic[1]) == 0){
      SumTemp$fstatistic[1] <- NA
    } # if f-statistic doesn't exist, assign NA to it
    Feeding_Type<- append(Feeding_Type, i) # append feeding type
    Life_Stage <- append(Life_Stage, j) # append life stage
    Regression_Slope <- append(Regression_Slope, SumTemp$coefficients[2]) # append regression slope
    Regression_Intercept <- append(Regression_Intercept, SumTemp$coefficients[1]) # append regression intercept
    R_Squared <- append(R_Squared, SumTemp$r.squared) # append R^2
    F_Statistic_Value <- append(F_Statistic_Value, SumTemp$fstatistic[1]) # append F-statistic value
    P_Value <- append(P_Value, SumTemp$coefficients[8]) # append p-value
    
    }
}

PPDF <- data.frame(Feeding_Type, Life_Stage, Regression_Slope, Regression_Intercept, R_Squared, F_Statistic_Value, P_Value)
# create a dataframe of regression results corresponding to the lines fitted in the figure
write.csv(PPDF, "../results/PP_Regress_Results.csv") # save the dataframe to a csv delimited table
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************
null device 
          1 

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
`geom_smooth()` using formula 'y ~ x'
Warning messages:
1: In qt((1 - level)/2, df) : NaNs produced
2: In max(ids, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf

======================================================================
Inspecting script file grahic.R...

File contents are:

**********************************************************************
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")
dim(MyDF) #check the size of the data frame you loaded
str(MyDF)
head(MyDF)
#apply dplyr to tidy the data
require(tidyverse)
glimpse(MyDF)

## remember to turn some column to factor to set them as grouping variables.
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)
MyDF$Location <- as.factor(MyDF$Location)
str(MyDF)

##scatter plots
plot(MyDF$Predator.mass, MyDF$Prey.mass)
plot(log(MyDF$Predator.mass), log(MyDF$Prey.mass))
plot(log10(MyDF$Predator.mass),log10(MyDF$Prey.mass))
plot(log10(MyDF$Predator.mass),log10(MyDF$Prey.mass),pch=20) # Change marker
plot(log10(MyDF$Predator.mass),log10(MyDF$Prey.mass),pch=20, xlab = "Predator Mass (g)", ylab = "Prey Mass (g)") # Add labels


##histgrams
hist(MyDF$Predator.mass)
hist(log10(MyDF$Predator.mass), xlab = "log10(Predator Mass (g))", ylab = "Count") # include labels
hist(log10(MyDF$Predator.mass),xlab="log10(Predator Mass (g))",ylab="Count", 
    col = "lightblue", border = "pink") # Change bar and borders colors 


#subplots
#use par to segment different graph to show there difference

par(mfcol=c(2,1)) #initialize multi-paneled plot
par(mfg = c(1,1)) # specify which sub-plot to use first 
hist(log10(MyDF$Predator.mass),
    xlab = "log10(Predator Mass (g))", ylab = "Count", col = "lightblue", border = "pink", 
    main = 'Predator') # Add title
par(mfg = c(2,1)) # Second sub-plot
hist(log10(MyDF$Prey.mass), xlab="log10(Prey Mass (g))",ylab="Count", col = "lightgreen", border = "pink", main = 'prey')

#overlaying plots
hist(log10(MyDF$Predator.mass), # Predator histogram
    xlab="log10(Body Mass (g))", ylab="Count", 
    col = rgb(1, 0, 0, 0.5), # Note 'rgb', fourth value is transparency
    main = "Predator-prey size Overlap") 
hist(log10(MyDF$Prey.mass), col = rgb(0, 0, 1, 0.5), add = T) # Plot prey
legend('topleft',c('Predators','Prey'),   # Add legend
    fill=c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5))) # Define legend colors

#Boxplots
boxplot(log10(MyDF$Predator.mass), xlab = "Location", ylab = "log10(Predator Mass)", main = "Predator mass")

boxplot(log(MyDF$Predator.mass) ~ MyDF$Location, # Why the tilde?
    xlab = "Location", ylab = "Predator Mass",
    main = "Predator mass by location")

boxplot(log(MyDF$Predator.mass) ~ MyDF$Type.of.feeding.interaction,
    xlab = "Location", ylab = "Predator Mass",
    main = "Predator mass by feeding interaction type")

#Combine plot types!!! importance the connection work

 par(fig=c(0,0.8,0,0.8)) # specify figure size as proportion
 plot(log(MyDF$Predator.mass),log(MyDF$Prey.mass), xlab = "Predator Mass (g)", ylab = "Prey Mass (g)") # Add labels
 par(fig=c(0,0.8,0.4,1), new=TRUE)
 boxplot(log(MyDF$Predator.mass), horizontal=TRUE, axes=FALSE)
 par(fig=c(0.55,1,0,0.8),new=TRUE)
 boxplot(log(MyDF$Prey.mass), axes=FALSE)
 mtext("Fancy Predator-prey scatterplot", side=3, outer=TRUE, line=-3)

##intro the pdf output methods
pdf("../results/Pred_Prey_Overlay.pdf", # Open blank pdf page using a relative path
    11.7, 8.3) # These numbers are page dimensions in inches
hist(log(MyDF$Predator.mass), # Plot predator histogram (note 'rgb')
    xlab="Body Mass (g)", ylab="Count", col = rgb(1, 0, 0, 0.5), main = "Predator-Prey Size Overlap") 
hist(log(MyDF$Prey.mass), # Plot prey weights
    col = rgb(0, 0, 1, 0.5), 
    add = T)  # Add to same plot = TRUE
legend('topleft',c('Predators','Prey'), # Add legend
    fill=c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5))) 
graphics.off(); #you can also use dev.off() 









**********************************************************************

Testing grahic.R...

Output (only first 500 characters): 


**********************************************************************
[1] 34931    15
'data.frame':	34931 obs. of  15 variables:
 $ Record.number              : int  1 2 3 4 5 6 7 8 9 10 ...
 $ In.refID                   : chr  "ATSH063" "ATSH080" "ATSH089" "ATSH143" ...
 $ IndividualID               : chr  "1" "2" "3" "4" ...
 $ Predator                   : chr  "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" ...
 $ Predator.common.name       : chr  "Atlantic sharpnose shark" "Atlantic sharpnose s
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: get_TreeHeight.R
# Date: Dec 2022
# Desc: 
# Function to calculate tree height and strip the .csv

#Function to calculate tree height and strip the .csv
Cal_TH <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    
    return(height)
}

#By creating an interactive interface, R programs can be run on LInux with command line parameters
args <- commandArgs(trailingOnly = TRUE)

output <- gsub("/|../data/|.csv","",args) #Remove file extension and relative path



Treedata <- read.csv(args)
Treedata$Tree.Height.m <- Cal_TH(Treedata$Angle.degrees, Treedata$Distance.m)

#put the result into a file in results folder
write.csv(Treedata, paste("../results/", output, "_treeheights.csv", sep = ""), row.names = FALSE)
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in file(file, "rt") : invalid 'description' argument
Calls: read.csv -> read.table -> file
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list = ls())

stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{

  N <- matrix(NA, numyears, length(p0))  
  #initialize empty matrix

  N[1, ] <- p0

  for (pop in 1:length(p0)) { 
    #loop through the populations
    for (yr in 2:numyears){ 
      #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) 
      # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)

}

# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 

stochrickvect <- function(p1 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears1 = 100)
{

  N <- matrix(NA, numyears1, length(p1))  #initialize empty matrix

  N[1, ] <- p1
    for (yr in  2:numyears1){
      
      N[yr,] <- N[yr-1, ] * exp(r * (1 - N[yr - 1,] / K) + rnorm(1, 0, sigma)) 
    }
  

  return(N)
} 




print("Un-vectorized Stochastic Ricker of Vectorize2.R takes:")
print(system.time(res2<-stochrick()))

print("Vectorized Stochastic Ricker of Vectorize2.R takes:")
print(system.time(res2<-stochrickvect()))

**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Un-vectorized Stochastic Ricker of Vectorize2.R takes:"
   user  system elapsed 
  0.210   0.021   0.230 
[1] "Vectorized Stochastic Ricker of Vectorize2.R takes:"
   user  system elapsed 
  0.009   0.000   0.009 

**********************************************************************

Code ran without errors

Time consumed = 0.46730s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################
rm(list=ls())
############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0
MyData
############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data
head(TempData)
rownames(TempData)<- NULL
head(TempData)
dim(TempData)

############# Convert from wide to long format using tidyverse ###############
require(tidyverse) # load the tidyverse

MyWrangledData<- gather(TempData,key = "Species",value="Count", -Cultivation,-Block,-Plot, -Quadrat,factor_key = TRUE)

head(MyWrangledData);tail(MyWrangledData)

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 

MyWrangledData<- dplyr::as_tibble(MyWrangledData)
MyWrangledData
#which is the same as commond
MyWrangledData<- as_tibble(MyWrangledData)
class(MyWrangledData)
## continue tidy data comond
glimpse(MyWrangledData) #like str(), but nicer!

filter(MyWrangledData, Count>100) #like subset(), but nicer!

slice(MyWrangledData, 10:15) # Look at a particular range of data rows
#group the data and calculate each mean
MyWrangledData %>% group_by(Species) %>% summarise(agv= mean(Count))


**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
There were 41 warnings (use warnings() to see them)

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
##pre-allocation

#explaint the reason  why they need re-preakllocation
NoPreallocFun <-function(x) {
    a <- vector() #empty vector
    for  (i in 1:x) {
        a <- c(a,i)
        print(a)
        print(object.size(a))
    }
}

system.time(NoPreallocFun(10))


#the true pre-allocation mehthod
PrealloFun <- function(x) {
    a <- rep(NA, x) #pre-allocation for vector
    for (i in 1:x) {
        a[i] <- i #assign
        print(a)
        print(object.size(a))
    }
}


system.time(PrealloFun(10))


**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
56 bytes
[1] 1 2
56 bytes
[1] 1 2 3
64 bytes
[1] 1 2 3 4
64 bytes
[1] 1 2 3 4 5
80 bytes
[1] 1 2 3 4 5 6
80 bytes
[1] 1 2 3 4 5 6 7
80 bytes
[1] 1 2 3 4 5 6 7 8
80 bytes
[1] 1 2 3 4 5 6 7 8 9
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10
96 bytes
   user  system elapsed 
  0.031   0.000   0.031 
 [1]  1 NA NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2 NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3 NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4 NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4  5 NA N
**********************************************************************

Code ran without errors

Time consumed = 0.37850s

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************



i <- 0 #Initialize i
    while (i < Inf) {
        if (i == 10) {
            break 
        } else { # Break out of the while loop!  
            cat("i equals " , i , " \n")
            i <- i + 1 # Update i
    }
}
**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.23887s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:

**********************************************************************
#!/bin/sh
# Author: 01_Awesome_Aardvarks
# Script: run_get_TreeHeight.sh
# Description: runs get_TreeHeight.R and get_TreeHeight.py using tree.csv as an argument
# Arguments: None
# Date: Dec 2022

# test the R script
Rscript get_TreeHeight.R ../data/trees.csv

# test the python script
python3 get_TreeHeight.py ../data/trees.csv
**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.35653s

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data
head(TempData)
rownames(TempData)<- NULL
head(TempData)
############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")
head(MyWrangledData);tail(MyWrangledData)

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############
#now is the time to use tidyverse 

#load tidyverse
require(tidyverse)

tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 

MyWrangledData<- dplyr::as_tibble(MyWrangledData)
MyWrangledData
#which is the same as commond
MyWrangledData<- as_tibble(MyWrangledData)
class(MyWrangledData)
## continue tidy data comond
glimpse(MyWrangledData) #like str(), but nicer!

filter(MyWrangledData, Count>100) #like subset(), but nicer!

slice(MyWrangledData, 10:15) # Look at a particular range of data rows
#group the data and calculate each mean
MyWrangledData %>% group_by(Species) %>% summarise(agv= mean(Count))
#there still some other command using 
#aggregate(MyWrangledData$Count, list(MyWrangledData$Species), FUN=mean) 








**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: reshape2
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file compilelatex.sh...

File contents are:

**********************************************************************
#
pdflatex is_Florida_getting_warmer.tex

#
rm *.aux
rm *.log
**********************************************************************

Testing compilelatex.sh...

Output (only first 500 characters): 


**********************************************************************
This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2022/dev/Debian) (preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./is_Florida_getting_warmer.tex
LaTeX2e <2021-11-15> patch level 1
L3 programming layer <2022-01-21>
(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls
Document Class: article 2021/10/04 v1.4n Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo))
(/usr/share/texlive/texmf-dist/tex/latex/blindtext/blin
**********************************************************************

Code ran without errors

Time consumed = 0.39918s

======================================================================
Inspecting script file Mybars.R...

File contents are:

**********************************************************************

########Annotating plots

a <- read.table("../data/Results.txt", header = TRUE)

head(a)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 
p

pdf("../results/MyBars.pdf")
print(p)

dev.off()

**********************************************************************

Testing Mybars.R...

Output (only first 500 characters): 


**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(a) : could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
rm(list=ls()) #first empty all variables

#load the tree.csv
Tdata<- read.csv("../data/trees.csv")
str(Tdata)                             ##clearfy the structure of data


# calculation functions setting up
TreeHeight <- function(degrees, distance) {
    radians <- degrees *pi /180
    height <- distance * tan(radians)
    return (height)
}

# apply the function to calculate the tree height in trees.csv
Tree.Height.m<- TreeHeight(Tdata$Angle.degrees, Tdata$Distance.m)
Tree.Height.m
Tdata$Tree.Height.m <- Tree.Height.m
str(Tdata)

# write the output into a new file
write.table(Tdata[1:2,],"../results/TreeHts.csv",row.names = FALSE )


**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************
'data.frame':	120 obs. of  3 variables:
 $ Species      : chr  "Populus tremula" "Quercus robur" "Ginkgo biloba" "Fraxinus excelsior" ...
 $ Distance.m   : num  31.7 46 31.2 34.6 45.5 ...
 $ Angle.degrees: num  41.3 44.5 25.1 23.3 38.3 ...
  [1] 27.80212 45.24603 14.66548 14.93418 35.97036 32.41021 17.45824 30.13738
  [9] 20.31248 24.43166 27.50213 25.15590 29.39248 28.18639 30.73989 39.73756
 [17] 24.69074 17.75982 20.81735 35.04535 31.85708 31.93860 13.48215 33.32665
 [25] 30.23270 35.95132 21.
**********************************************************************

Code ran without errors

Time consumed = 0.20419s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv",append=TRUE) 
write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names=FALSE) 
**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Warning message:
In write.table(MyData[1, ], file = "../results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M) {
    Dimensions <- dim(M)
    Tot <- 0
    for (i in 1:Dimensions[1]) {
        for (j in 1:Dimensions[2]) {
            Tot <- Tot +M[i,j]
        }
    }
    return (Tot)
}

print("Using loops, he time taken is :")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the wimt taken is :")
print(system.time(sum(M)))


**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, he time taken is :"
   user  system elapsed 
  0.065   0.005   0.070 
[1] "Using the in-built vectorized function, the wimt taken is :"
   user  system elapsed 
  0.001   0.000   0.001 

**********************************************************************

Code ran without errors

Time consumed = 0.33582s

======================================================================
======================================================================
Finished running scripts

Ran into 13 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 93.0

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!